# extract.py
from pyspark.sql import DataFrame, SparkSession
from pyspark.sql.functions import lit
import os
from openpyxl import load_workbook  # Seulement pour lister les feuilles (sans pandas)
import xlrd  # Installer avec: pip install xlrd
def list_excel_sheets(excel_path: str) -> list:
    """
    Liste les noms de feuilles du fichier Excel (.xls).
    """
    wb = xlrd.open_workbook(excel_path, on_demand=True)
    sheets = wb.sheet_names()
    wb.release_resources()
    return sheets

def extract_data(spark: SparkSession, excel_path: str) -> DataFrame:
    """
    Extrait et fusionne les donn√©es des feuilles Excel (sauf la premi√®re) en un DataFrame Spark.
    Utilise spark-excel pour lire chaque feuille √† partir de la 4√®me ligne (A4).
    """
    sheets = list_excel_sheets(excel_path)
    # On ignore la premi√®re feuille (par exemple une feuille d'informations)
    sheets_to_read = sheets[1:]
    df_list = []
    for sheet in sheets_to_read:
        print(f"üìÑ Traitement de la feuille : {sheet}")
        dataAddress = f"'{sheet}'!A4"  # Lecture √† partir de la 4√®me ligne
        df_sheet = spark.read.format("com.crealytics.spark.excel") \
            .option("dataAddress", dataAddress) \
            .option("useHeader", "true") \
            .option("inferSchema", "true") \
            .option("treatEmptyValuesAsNulls", "true") \
            .option("addColorColumns", "false") \
            .load(excel_path)
        # Ajout de la colonne Ann√©e (issu du nom de la feuille)
        df_sheet = df_sheet.withColumn("Ann√©e", lit(sheet))
        df_list.append(df_sheet)
    if df_list:
        df_all = df_list[0]
        for df in df_list[1:]:
            df_all = df_all.unionByName(df)
        return df_all
    else:
        raise ValueError("Aucune feuille trouv√©e dans le fichier Excel.")
