# loader.py

import logging
import os
import shutil

logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)


class DataLoader:
    """
    Classe permettant d'enregistrer un DataFrame PySpark transform√© en fichier CSV.
    Le fichier est nomm√© selon le format "<nom_fichier_base>_processed.csv".
    """

    def __init__(self, output_dir="data\processed_data"):
        """
        Initialise le DataLoader avec un r√©pertoire de sortie.

        :param output_dir: Dossier o√π seront stock√©s les fichiers CSV transform√©s.
        """
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)  # Cr√©e le dossier s'il n'existe pas

    def save_to_csv(self, df, input_file_path):
        """
        Sauvegarde un DataFrame en fichier CSV apr√®s transformation.

        :param df: DataFrame PySpark transform√©
        :param input_file_path: Chemin du fichier source initial
        """
        if df is None:
            logger.error("‚ùå Impossible de sauvegarder un DataFrame vide.")
            return

        base_name = os.path.basename(input_file_path).replace(".csv", "_processed.csv")
        final_output_path = os.path.join("data/processed_data", base_name)

        logger.info(
            f"üíæ Enregistrement des donn√©es transform√©es dans : {final_output_path}"
        )

        try:
            # Utiliser toPandas() pour les petits datasets ou repartition() pour les grands
            if df.count() < 1000000:  # Seuil arbitraire, √† ajuster selon vos besoins
                # M√©thode pour petits datasets
                df.toPandas().to_csv(final_output_path, index=False)
            else:
                # M√©thode pour grands datasets
                df.repartition(1).write.mode("overwrite").option("header", "true").csv(
                    final_output_path + "_temp"
                )

                # Renommer le fichier g√©n√©r√©
                for filename in os.listdir(final_output_path + "_temp"):
                    if filename.endswith(".csv"):
                        os.rename(
                            os.path.join(final_output_path + "_temp", filename),
                            final_output_path,
                        )

            # Nettoyer le dossier temporaire
            shutil.rmtree(final_output_path + "_temp")

            logger.info("‚úÖ Fichier CSV sauvegard√© avec succ√®s !")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'enregistrement du fichier : {str(e)}")
