# loader.py

import logging
import os
import shutil
import pandas as pd
from typing import Optional

# Configuration du logger
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class DataLoader:
    """
    Classe permettant d'enregistrer un DataFrame PySpark transform√© en fichier CSV.
    Le fichier est nomm√© selon le format "<nom_fichier_base>_processed.csv".
    """

    def __init__(self, output_dir="data\processed_data"):
        """
        Initialise le DataLoader avec un r√©pertoire de sortie.

        :param output_dir: Dossier o√π seront stock√©s les fichiers CSV transform√©s.
        """
        logger.info(
            f"üöÄ Initialisation du DataLoader avec le dossier de sortie : {output_dir}"
        )
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)  # Cr√©e le dossier s'il n'existe pas
        logger.info("‚úÖ Dossier de sortie cr√©√©/valid√©")

    def save_to_csv(self, df, input_file_path):
        """
        Sauvegarde un DataFrame en fichier CSV apr√®s transformation.

        :param df: DataFrame PySpark transform√©
        :param input_file_path: Chemin du fichier source initial
        """
        if df is None:
            logger.error("‚ùå Impossible de sauvegarder un DataFrame vide.")
            return

        # Normaliser le chemin d'entr√©e
        input_file_path = os.path.normpath(input_file_path)

        # Cr√©er le nom du fichier de sortie
        base_name = os.path.basename(input_file_path).replace(".csv", "_processed.csv")
        final_output_path = os.path.normpath(os.path.join(self.output_dir, base_name))
        temp_output_path = os.path.normpath(
            os.path.join(self.output_dir, f"{base_name}_temp")
        )

        logger.info(
            f"‚ö° Enregistrement des donn√©es transform√©es dans : {final_output_path}"
        )

        try:
            # Utiliser toPandas() pour les petits datasets ou repartition() pour les grands
            if df.count() < 1000000:  # Seuil arbitraire, √† ajuster selon vos besoins
                # M√©thode pour petits datasets
                df.toPandas().to_csv(final_output_path, index=False)
            else:
                # M√©thode pour grands datasets
                df.repartition(1).write.mode("overwrite").option("header", "true").csv(
                    temp_output_path
                )

                # Renommer le fichier g√©n√©r√©
                for filename in os.listdir(temp_output_path):
                    if filename.endswith(".csv"):
                        os.rename(
                            os.path.join(temp_output_path, filename), final_output_path
                        )

                # Nettoyer le dossier temporaire
                if os.path.exists(temp_output_path):
                    shutil.rmtree(temp_output_path)

            logger.info("‚úÖ Fichier CSV sauvegard√© avec succ√®s !")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'enregistrement du fichier : {str(e)}")
            # Nettoyer le dossier temporaire en cas d'erreur
            if os.path.exists(temp_output_path):
                shutil.rmtree(temp_output_path)
